# -*- coding: utf-8 -*-
"""NN4I_EX2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F4n1fJ3iKcGBJEiYqzS5Kht8Zu19Mj2T
"""

#@markdown **NOTE**: It is strongly advised you save your results to Google 
#@markdown Drive as they will be deleted from Colab once it restarts. 
#@markdown To connect Google Drive run this cell. 
from google.colab import drive
drive.mount('/content/gdrive/')

!pip install wandb

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
import wandb

DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
PATH = '/content/gdrive/MyDrive/NN4I/exercise2/'

"""**General Helper Functions**"""

def save_traied_module(net, path):
    print('Save trained module in path: ' + path)
    torch.save(net.state_dict(), path)

def load_traied_module(path, is_encoder, d):
    print('Load trained module from path: ' + path)
    if is_encoder:
      net = Encoder_module(d)
    else:
      net = Decoder_module(d)
    
    net.load_state_dict(torch.load(path))
    net.eval()
    return net

def wandb_login(project_name, num_of_epochs, batch_size, lr, latent_dimension):
  #For tester: I censored the wandb api and commented all the WANDB parts so the code be able to work
  wandb.login(relogin=True, key="***")
  wandb.init(project=project_name,
            config={
                "num_of_epochs": num_of_epochs,
                "batch_size": batch_size,
                "lr": lr,
                "latent_dimension": latent_dimension
            })

"""**QUESTION 1**"""

# Encoder / Decoder module classes
class Encoder_module(nn.Module):
  def __init__(self, d):
    super().__init__()
    self.encoder_conv_layers = nn.Sequential(
      # First convolutional layer
      nn.Conv2d(1, 9, 3, stride=2, padding=1),
      nn.BatchNorm2d(9),
      nn.ReLU(True),
      # Second convolutional layer
      nn.Conv2d(9, 18, 3, stride=2, padding=1),
      nn.BatchNorm2d(18),
      nn.ReLU(True),
      # Third convolutional layer
      nn.Conv2d(18, 36, 3, stride=2, padding=0),
      nn.BatchNorm2d(36),
      nn.ReLU(True)
    )

    self.encoder_fc_layer =  nn.Sequential(
      # Fully Connected Layer
      nn.Linear(36 * 3 * 3, d),
      nn.ReLU(True),
    )


  def forward(self, x):
    x = self.encoder_conv_layers(x)
    x = torch.flatten(x, 1)
    x = self.encoder_fc_layer(x)

    return x

class Decoder_module(nn.Module):
  def __init__(self, d):
    super().__init__()
    self.dencoder_conv_layers = nn.Sequential(
      # First transposed convolution layer
      nn.ConvTranspose2d(36, 18, 3, stride=2, output_padding=0),
      nn.BatchNorm2d(18),
      nn.ReLU(True),
      # Second transposed convolution layer
      nn.ConvTranspose2d(18, 9, 3, stride=2, padding=1, output_padding=1),
      nn.BatchNorm2d(9),
      nn.ReLU(True),
      # Third transposed convolution layer
      nn.ConvTranspose2d(9, 1, 3, stride=2, padding=1, output_padding=1),
      nn.Sigmoid()
    )

    self.dencoder_fc_layer =  nn.Sequential(
        # Fully Connected Layer
        nn.Linear(d, 36 * 3 * 3),
        nn.ReLU(True)
    )

  def forward(self, x):
    x = self.dencoder_fc_layer(x)
    x = torch.reshape(x, (x.shape[0], 36, 3, 3))
    x = self.dencoder_conv_layers(x)

    return x

def load_MNIST_and_normalize():
    transform = transforms.Compose([transforms.ToTensor()])

    train_set = torchvision.datasets.MNIST(root='./MNIST_train_data', train=True,
                                          download=True, transform=transform)

    test_set = torchvision.datasets.MNIST(root='./MNIST_test_data', train=False,
                                         download=True, transform=transform)
    
    return train_set, test_set

def create_loader(dataset, batch_size=4):
  loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, 
                                       shuffle=True, num_workers=2)
  return loader

def test_AE_module(encoder_net, decoder_net, dataset, batch_size, full=False):
  loss = 0.0
  num_of_baches = 0
  loss_func = nn.MSELoss()
  loader = create_loader(dataset, batch_size)
  encoder_net.eval()
  decoder_net.eval()

  with torch.no_grad():
    for data in loader:
      images_batch = data[0].to(DEVICE)
      # Encode and Decode the given images batch using encoder_net & dencoder_net
      encoded_data = encoder_net(images_batch)
      decoded_data = decoder_net(encoded_data)

      # Update loss variables
      loss += loss_func(decoded_data, images_batch).item()
      num_of_baches += 1
      if not full and num_of_baches >= 200:
        break

  loss = round(loss / num_of_baches, 3)

  return loss

def train_AE_module(latent_dimension, num_of_epochs, batch_size, learning_rate, 
                    report_losses=False, save_network=False):

  # Load data and normalize
  trainset, testset = load_MNIST_and_normalize()
  trainloader = create_loader(trainset, batch_size)
  testloader = create_loader(testset, batch_size)

  # Initiate encoder and decoder modules
  print("latent_dimension=%d" % latent_dimension)
  encoder_net = Encoder_module(d=latent_dimension)
  decoder_net = Decoder_module(d=latent_dimension)

  AE_params = [
      {'params': encoder_net.parameters()},
      {'params': decoder_net.parameters()}
  ]

  encoder_net = encoder_net.to(DEVICE)
  decoder_net = decoder_net.to(DEVICE)

  encoder_params_num = sum(p.numel() for p in encoder_net.parameters() if p.requires_grad)
  decoder_params_num = sum(p.numel() for p in decoder_net.parameters() if p.requires_grad)
  print("Encoder parameters: %d" % encoder_params_num)
  print("Decoder parameters: %d" % decoder_params_num)
  print("Sum prameters: %d" % (encoder_params_num + decoder_params_num))
  
  # Define a Loss function and optimizer
  loss_func = nn.MSELoss()
  optimizer = optim.SGD(AE_params, lr=learning_rate, momentum=0.9)

  # Start training networks
  print('Starting Training Auto Encoder Module')

  for epoch in range(num_of_epochs):  # loop over the dataset multiple times

    for i, data in enumerate(trainloader, 0):
      # Set network to training mode
      encoder_net.train()
      decoder_net.train()

      # get the inputs images
      inputs_batch = data[0].to(DEVICE)

      # zero the parameter gradients
      optimizer.zero_grad()

      # forward + backward + optimize
      encoded_batch = encoder_net(inputs_batch)
      decoded_batch = decoder_net(encoded_batch)
      loss = loss_func(decoded_batch, inputs_batch)
      loss.backward()
      optimizer.step()

      # Compute train-loss, train-accuracy, test-loss and test-accuracy if the network every 50 batch
      if report_losses and i % 375 == 374:
        train_loss = test_AE_module(encoder_net, decoder_net, trainset, batch_size)
        test_loss = test_AE_module(encoder_net, decoder_net, testset, batch_size)
        wandb.log({'train loss': train_loss, 'test loss': test_loss})
        print("epoch={}: train loss={}, test loss={}".format(epoch, train_loss, test_loss))

  print('Finished Training Auto Encoder Module')
  train_loss = test_AE_module(encoder_net, decoder_net, trainset, batch_size, full=True)
  test_loss = test_AE_module(encoder_net, decoder_net, testset, batch_size, full=True)
  print("train loss={}, test loss={}".format(train_loss, test_loss))

  if save_network:
    save_traied_module(encoder_net, PATH + 'encoder_{}'.format(latent_dimension))
    save_traied_module(decoder_net, PATH + 'decoder_{}'.format(latent_dimension))
  
  return encoder_net, decoder_net

# Question 1 - MAIN CODE
project_name = "NN4Images_ex2.Q1"
num_of_epochs = 20
batch_size = 32
lr = 0.001

#wandb_login(project_name, num_of_epochs, batch_size, lr, latent_dimension)
for latent_dimension in [1, 5, 10, 15, 20, 50, 100]: 
  train_AE_module(latent_dimension, num_of_epochs, batch_size, lr, report_losses=False, save_network=True)

"""**QUESTION 2**"""

def get_sample_image(digit):
  # This function returns an image with the desired digit from the training dataset of MNIST
  # Load data and normalize
  trainset, _ = load_MNIST_and_normalize()
  trainloader = create_loader(trainset, 1)

  for data in trainloader:
    image, lable = data[0].to(DEVICE), data[1].to(DEVICE)
    if lable == digit:
      return image

def digits_interpolation(digit1, digit2, num_of_images):
  # Retrive sample images for each digit
  image1 = get_sample_image(digit1)
  image2 = get_sample_image(digit2)

  _, axarr = plt.subplots(2, num_of_images)

  for i, d in enumerate([20, 100]):
    # Load encoder and decoder networks
    encoder_net = load_traied_module(path=PATH + 'encoder_{}'.format(d), is_encoder=True, d=d)
    decoder_net = load_traied_module(path=PATH + 'decoder_{}'.format(d), is_encoder=False, d=d)
    encoder_net = encoder_net.to(DEVICE)
    decoder_net = decoder_net.to(DEVICE)

    # Perform an interpolation between the two digits
    latent_digit1 = encoder_net(image1)
    latent_digit2 = encoder_net(image2)

    for j, alpha in enumerate(np.linspace(0., 1., num_of_images)):
      latent_vector = (1 - alpha) * latent_digit1 + alpha * latent_digit2
      new_image = decoder_net(latent_vector)
      np_image = torch.squeeze(new_image, (0, 1)).detach().cpu().numpy()
      axarr[i][j].imshow(np_image, cmap='gray', vmin=0.0, vmax=1.0)
    
  plt.show()

# Question 2 - MAIN CODE
digits_interpolation(3, 5, 7)
digits_interpolation(5, 8, 7)
digits_interpolation(0, 4, 7)
digits_interpolation(2, 9, 7)

"""**QUESTION 3**"""

def decorrelation(encoder_net, num_of_samples):
  # Load data and normalize
  trainset, _ = load_MNIST_and_normalize()
  trainloader = create_loader(trainset, num_of_samples)
  data = next(iter(trainloader))
  images_batch = data[0].to(DEVICE)

  # Use the encoder model to get a sample of vectors in the latent space
  encoder_net.eval()
  latent_tensor = encoder_net(images_batch)

  # Compute the Pearson correlation coefficient for each pair of indices
  latent_tensor = torch.transpose(latent_tensor, 0, 1)
  coff_tensor = torch.corrcoef(latent_tensor)
  # Some of the coefficient can be 'nan', replace them with zero
  coff_tensor = torch.nan_to_num(coff_tensor)
  # convert correlation coefficient to absolute values
  coff_tensor = torch.abs(coff_tensor)
  # Calculate the mean value accross all the coefficients of diffrent indices pairs
  d = coff_tensor.shape[0]
  mean_corr_coeff = float(torch.sum(torch.triu(coff_tensor, diagonal=1))) * (2 / (d * (d - 1)))
  return mean_corr_coeff

# Question 3 - MAIN CODE
num_of_samples = 5000
latent_dimensions = [5, 10, 15, 20]
mean_corr_coeff = []
for dimension in latent_dimensions:
  encoder_net = load_traied_module(path=PATH + 'encoder_{}'.format(dimension), is_encoder=True, d=dimension)
  encoder_net = encoder_net.to(DEVICE)
  mean_corr_coeff.append(decorrelation(encoder_net, num_of_samples))

print(mean_corr_coeff)
plt.plot(latent_dimensions, mean_corr_coeff, 'ro')
plt.show()

"""**QUESTION 4**"""

class MLP_module(nn.Module):
  def __init__(self, d):
    super().__init__()
    self.mlp_fc_layer =  nn.Sequential(
      # Fully Connected Layer
      nn.Linear(d, 50),
      nn.ReLU(True),
      nn.Linear(50, 100),
      nn.ReLU(True),
      nn.Linear(100, 10),
      nn.Softmax(dim=1)
    )


  def forward(self, x):
    x = self.mlp_fc_layer(x)
    return x

def test_MNIST_classifier_module(encoder_net, mlp_net, dataset, batch_size):
  loss = 0.0
  num_of_baches = 0
  loss_func = nn.CrossEntropyLoss()
  loader = create_loader(dataset, batch_size)
  encoder_net.eval()
  mlp_net.eval()

  with torch.no_grad():
    for data in loader:
      images_batch, true_labels = data[0].to(DEVICE), data[1].to(DEVICE)
      # Convert the true lables to one-hot vectors
      true_labels = F.one_hot(true_labels, num_classes=10) * 1.
      # Activate the encode and mlp modules
      encoded_data = encoder_net(images_batch)
      output_labels = mlp_net(encoded_data)

      # Update loss variables
      loss += loss_func(output_labels, true_labels).item()
      num_of_baches += 1

  loss = round(loss / num_of_baches, 3)
  return loss

def train_MNIST_classifier_module(latent_dimension, num_of_epochs, learning_rate,
                                  training_data, encoder_net , train_encoder=False):
  # Initiate mlp module
  mlp_net = MLP_module(d=latent_dimension)

  classifier_params = [
      {'params': mlp_net.parameters()}
  ]

  if train_encoder:
    classifier_params.insert(0, {'params': encoder_net.parameters()})

  encoder_net = encoder_net.to(DEVICE)
  mlp_net = mlp_net.to(DEVICE)

  # Define a Loss function and optimizer
  loss_func = nn.CrossEntropyLoss()
  optimizer = optim.SGD(classifier_params, lr=learning_rate, momentum=0.9)

  # Start training networks
  print('Starting Training MNIST Classifier Module')

  for epoch in range(num_of_epochs):  # loop over the dataset multiple times

    # Set network to training / eval mode
    mlp_net.train()
    if train_encoder:
      encoder_net.train()
    else:
      encoder_net.eval()
    
    # Get the inputs images and their true labels
    inputs_batch, true_labels = training_data[0].to(DEVICE), training_data[1].to(DEVICE)

    # Convert the true lables to one-hot vectors
    true_labels = F.one_hot(true_labels, num_classes=10) * 1.

    # zero the parameter gradients
    optimizer.zero_grad()

    # forward + backward + optimize
    encoded_batch = encoder_net(inputs_batch)
    outputs_labels = mlp_net(encoded_batch)

    loss = loss_func(outputs_labels, true_labels)
    loss.backward()
    optimizer.step()

  print('Finished Training MNIST Classifier Module')

  return encoder_net, mlp_net

# Question4 - MAIN CODE 
# Load data and normalize
trainset , testset = load_MNIST_and_normalize()
trainloader = create_loader(testset, 50)
training_data =  next(iter(trainloader))

# Initilized Variables
latent_dimension = 20
num_of_epochs = 50
batch_size = 32
lr = 0.001

# Load traind encoder module
encoder_net = load_traied_module(path=PATH + 'encoder_{}'.format(latent_dimension), is_encoder=True, d=latent_dimension)

# Get training results for diffrent senarios:
# Senario 1 - Train ONLY the MLP module and print the final train and test losses
encoder_net, mlp_net = train_MNIST_classifier_module(latent_dimension, num_of_epochs, lr, training_data, encoder_net , train_encoder=False)
train_loss = test_MNIST_classifier_module(encoder_net, mlp_net, trainset, batch_size)
test_loss = test_MNIST_classifier_module(encoder_net, mlp_net, testset, batch_size)
print("First network senario: d={}, train loss={}, test loss={}".format(latent_dimension, train_loss, test_loss))

# Senario 2 - Train BOTH the Encoder and MLP modules and print the final train and test losses
encoder_net, mlp_net = train_MNIST_classifier_module(latent_dimension, num_of_epochs, lr, training_data, encoder_net , train_encoder=True)
train_loss = test_MNIST_classifier_module(encoder_net, mlp_net, trainset, batch_size)
test_loss = test_MNIST_classifier_module(encoder_net, mlp_net, testset, batch_size)
print("Second network senario: d={}, train loss={}, test loss={}".format(latent_dimension, train_loss, test_loss))