# -*- coding: utf-8 -*-
"""NN4I_EX3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L3Ojac4Ba93HSZ5sCZXUahg3vjGKrIeL
"""

#@markdown **NOTE**: It is strongly advised you save your results to Google 
#@markdown Drive as they will be deleted from Colab once it restarts. 
#@markdown To connect Google Drive run this cell. 
from google.colab import drive
drive.mount('/content/gdrive/',  force_remount=True)

!pip install wandb

import torch
import torchvision
import torchvision.transforms as transforms
import torchvision.utils as vutils
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
import wandb
from torch.utils.data import Dataset, DataLoader

"""**Global Variables**"""

DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
HOME_PATH = '/content/gdrive/MyDrive/NN4I/exercise3/'
CELEBA64_DATASET_PATH =  HOME_PATH + 'CelebA64.npy'
CELEBA64_DATA = np.load(CELEBA64_DATASET_PATH)
LATENT_SPACE_DIMENSION = 100
GEN_FEATURE_MAP_SIZE = 64
DISC_FEATURE_MAP_SIZE = 64
REAL_LABLE = 1
FAKE_LABLE = 0

"""**General Auxiliary Functions**"""

def load_CelebA64():
    transform = transforms.Compose([transforms.ToTensor()])
    dataset = CelebA64_dataset(CELEBA64_DATA, transform)
    
    return dataset

def create_loader(dataset, batch_size=4):
  loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, 
                                       shuffle=True, num_workers=2)
  return loader

def wandb_login(project_name, key, num_of_epochs, batch_size, lr, num_of_steps):
  #For tester: I censored the wandb api and commented all the WANDB parts so the code be able to work
  wandb.login(relogin=True, key=key)
  wandb.init(project=project_name,
            config={
                "num_of_epochs": num_of_epochs,
                "batch_size": batch_size,
                "lr": lr,
                "num_of_steps": num_of_steps
            })

def save_traied_module(net, path):
    print('Save trained module in path: ' + path)
    torch.save(net.state_dict(), path)

def load_traied_module(path, is_disc):
    print('Load trained module from path: ' + path)
    if is_disc:
      net = Discriminator_module()
    else:
      net = Generator_module() 
    
    net.load_state_dict(torch.load(path))
    net = net.to(DEVICE)
    net.eval()
    return net

# Custom weights initialization
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

def display_gen_images(gen_images):
  grid = vutils.make_grid(gen_images, padding=2, normalize=True)
  fig = plt.figure(figsize=(8,8))
  plt.axis("off")
  plt.imshow(np.transpose(grid,(1,2,0)), animated=True)
  plt.show()

"""**Custom dataset class for CelebA64**"""

# CelebA64 Dataset
class CelebA64_dataset(Dataset):
  def __init__(self, data, transform):
    self.data = data
    self.transform = transform

  def __getitem__(self, index):
    x = self.data[index]
    x = self.transform(x)
    return x

  def __len__(self):
    return len(self.data)

"""**GAN's Generator and Discriminator Modules**"""

# Generator / Discriminator module classes
class Generator_module(nn.Module):
  def __init__(self):
    super().__init__()
    self.generator_conv_layers = nn.Sequential(
      # First transposed convolution layer -> Current size = 100 x 1 x 1
      nn.ConvTranspose2d(LATENT_SPACE_DIMENSION, 8 * GEN_FEATURE_MAP_SIZE, kernel_size=4, stride=1, padding=0, bias=False),
      nn.BatchNorm2d(8 * GEN_FEATURE_MAP_SIZE),
      nn.ReLU(True),
      # Second transposed convolution layer -> Current size = 512 x 4 x 4
      nn.ConvTranspose2d(8 * GEN_FEATURE_MAP_SIZE, 4 * GEN_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.BatchNorm2d(4 * GEN_FEATURE_MAP_SIZE),
      nn.ReLU(True),
      # Third transposed convolution layer -> Current size = 256 x 8 x 8
      nn.ConvTranspose2d(4 * GEN_FEATURE_MAP_SIZE, 2 * GEN_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.BatchNorm2d(2 * GEN_FEATURE_MAP_SIZE),
      nn.ReLU(True),
      # Fourth transposed convolution layer -> Current size = 128 x 16 x 16
      nn.ConvTranspose2d(2 * GEN_FEATURE_MAP_SIZE, GEN_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.BatchNorm2d(GEN_FEATURE_MAP_SIZE),
      nn.ReLU(True),
      # Fifth transposed convolution layer -> Current size = 164 x 32 x 32
      nn.ConvTranspose2d(GEN_FEATURE_MAP_SIZE, 3, kernel_size=4, stride=2, padding=1, bias=False),
      nn.Tanh()
      # Final size = 3 x 64 x 64
    )

  def forward(self, x):
    x = torch.reshape(x, (x.shape[0], LATENT_SPACE_DIMENSION, 1, 1))
    x = self.generator_conv_layers(x)
    return x

  
class Discriminator_module(nn.Module):
  def __init__(self):
    super().__init__()
    self.discriminator_conv_layers = nn.Sequential(
      # First convolutional layer -> Current size = 3 x 64 x 64
      nn.Conv2d(3, DISC_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.LeakyReLU(0.2, inplace=True),
      # Second convolutional layer -> Current size = 64 x 32 x 32
      nn.Conv2d(DISC_FEATURE_MAP_SIZE, 2 * DISC_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.BatchNorm2d(2 * DISC_FEATURE_MAP_SIZE),
      nn.LeakyReLU(0.2, inplace=True),
      # Third convolutional layer -> Current size = 128 x 16 x 16
      nn.Conv2d(2 * DISC_FEATURE_MAP_SIZE, 4 * DISC_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.BatchNorm2d(4 * DISC_FEATURE_MAP_SIZE),
      nn.LeakyReLU(0.2, inplace=True),
      # Fourth convolutional layer -> Current size = 256 x 8 x 8
      nn.Conv2d(4 * DISC_FEATURE_MAP_SIZE, 8 * DISC_FEATURE_MAP_SIZE, kernel_size=4, stride=2, padding=1, bias=False),
      nn.BatchNorm2d(8 * DISC_FEATURE_MAP_SIZE),
      nn.LeakyReLU(0.2, inplace=True),
      # Fifth convolutional layer -> Current size = 512 x 4 x 4
      nn.Conv2d(8 * DISC_FEATURE_MAP_SIZE, 1, kernel_size=4, stride=1, padding=0, bias=False),
      nn.Sigmoid(),
      # Final size = 1 x 1 x 1
    )

  def forward(self, x):
    x = self.discriminator_conv_layers(x)
    return x

"""**Training GAN's Modules**"""

def discriminator_one_step(D_optimizer, D_module, G_images, real_images, sample_size):
  criterion = nn.BCELoss()
  real_labels = torch.full((sample_size,), REAL_LABLE, dtype=torch.float, device=DEVICE)
  D_outputs = D_module(real_images).view(-1)
  D_real_loss = criterion(D_outputs, real_labels)

  fake_labels = torch.full((sample_size,), FAKE_LABLE, dtype=torch.float, device=DEVICE)
  D_outputs = D_module(G_images.detach()).view(-1)
  D_fake_loss = criterion(D_outputs, fake_labels)

  D_loss = D_real_loss + D_fake_loss
  D_loss.backward()
  D_optimizer.step()

  return D_loss.item()

def generator_one_step(criterion_type, G_optimizer, D_module, G_images, sample_size):
  if criterion_type == 'bce_non_saturation':
    labels = torch.full((sample_size,), REAL_LABLE, dtype=torch.float, device=DEVICE)
    criterion = nn.BCELoss()
  elif criterion_type == 'bce_saturation':
    labels = torch.full((sample_size,), FAKE_LABLE, dtype=torch.float, device=DEVICE)
    criterion = nn.BCELoss()
  else: # criterion_type == 'mse'
    labels = torch.full((sample_size,), REAL_LABLE, dtype=torch.float, device=DEVICE)
    criterion = nn.MSELoss()
  
  D_outputs = D_module(G_images).view(-1)
  G_loss = criterion(D_outputs, labels)
  if criterion_type == 'bce_saturation':
    G_loss = -1 * G_loss

  G_loss.backward()
  G_optimizer.step()

  return G_loss.item()

def train_GAN_module(criterion_type, lr, num_of_epochs, batch_size, num_of_steps):
  # Load CelebA64 dataset
  dataset = load_CelebA64()
  dataloader = create_loader(dataset, batch_size=batch_size)

  # Initiate discriminator and generator modules
  disc_module = Discriminator_module()
  disc_module = disc_module.to(DEVICE)
  disc_module.apply(weights_init)
  disc_module.zero_grad()

  gen_module = Generator_module()
  gen_module = gen_module.to(DEVICE)
  gen_module.apply(weights_init)
  gen_module.zero_grad()

  # Initiate SGD Optimisers for discriminator and generator modules
  optimizerD = optim.Adam(disc_module.parameters(), lr=lr, betas=(0.5, 0.999))
  optimizerG = optim.Adam(gen_module.parameters(), lr=0.0001, betas=(0.5, 0.999))

  # Create a batch of latent vectors that will use to visualize rhe origression of the generator
  fixed_latent_vactors = torch.randn(64, LATENT_SPACE_DIMENSION, device=DEVICE)

  # Disply initial generator images before training
  with torch.no_grad():
    print("Generated images before training:")
    gen_inter_images = gen_module(fixed_latent_vactors).detach().cpu()
    display_gen_images(gen_inter_images)
  
  # Start training
  print("Start training GAN module")
  curr_num_of_steps = 0
  for epoch in range(num_of_epochs):
    for i, data in enumerate(dataloader, 0):
      curr_num_of_steps += 1
      real_images = data.to(DEVICE)
      sample_size = real_images.size(0)
      
      # Sample random images to be used by Generator module
      latent_vactors = torch.randn(sample_size, LATENT_SPACE_DIMENSION, device=DEVICE)
      gen_imeges = gen_module(latent_vactors)

      # Train Discriminator module for one optimization step
      disc_module.zero_grad()
      gen_module.zero_grad()
      disc_loss = discriminator_one_step(optimizerD, disc_module, gen_imeges, real_images, sample_size)

      # Train after several optimization steps performed on the Discriminator module,
      # train the Generator module for one optimization step
      if curr_num_of_steps % num_of_steps == 0:
        disc_module.zero_grad()
        gen_module.zero_grad()
        gen_loss = generator_one_step(criterion_type, optimizerG, disc_module, gen_imeges, sample_size)

        # Report current loss of Discriminator and Generator modules
        # wandb.log({'Discriminator loss': disc_loss, 'Generator loss': gen_loss})
        if curr_num_of_steps % 100 == 0:
          print("epoch={}: Discriminator loss={}, Generator loss={}".format(epoch, disc_loss, gen_loss))
    
    # Disply intermediate generator images
    with torch.no_grad():
      print("Generated images after {} epoches:".format(epoch + 1))
      gen_inter_images = gen_module(fixed_latent_vactors).detach().cpu()
      display_gen_images(gen_inter_images)
  

  print("Finished training GAN module")
  return disc_module, gen_module

"""**Question 1 - Train GAN Modules With Diffrent Generator Loss Criterions**"""

# Question 1 - train GAN module 
# For tester: I censored my wandb api and commented all the WANDB lines so the code be able to work

project_name = "DL4Images_ex3.Q1"
key = "****"
num_of_epochs = 5
batch_size = 128
lr = 0.0002
num_of_steps = 3

# wandb_login(project_name, key, num_of_epochs, batch_size, lr, num_of_steps)
criterion_type_lst = ["bce_non_saturation", "bce_saturation", "mse"]

for criterion_type in criterion_type_lst:
  suffix = "_criterion_type_{}".format(criterion_type)
  D_module_path = HOME_PATH + "Discriminator" + suffix
  G_module_path = HOME_PATH + "Generator" + suffix

  D_module, G_module = train_GAN_module(criterion_type, lr, num_of_epochs, batch_size, num_of_steps)

  save_traied_module(D_module, D_module_path)
  save_traied_module(G_module, G_module_path)

"""**Auxiliary Functions For Questions 2-3**"""

def display_three_images(images):
  images = torch.clamp(images, min=0.0, max=1.0)
  images = images.to('cpu').detach()
  images = images.numpy()
  images = images.transpose(0, 2, 3, 1)
  
  f, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3)
  ax0.imshow(images[0], vmin=0.0, vmax=1.0)
  ax1.imshow(images[1], vmin=0.0, vmax=1.0)
  ax2.imshow(images[2], vmin=0.0, vmax=1.0)

  ax0.title.set_text('Original image')
  ax1.title.set_text('Degradated image')
  ax2.title.set_text('Restored image')

  plt.show()

# Restoration function for questions 2 and 3
def restore_image(original_image, degradetion_func, criterion, min_err=1.0e-04, max_iter=4*10**5):
  # Step 0 - Dagradate original image
  degradeted_image = degradetion_func(original_image)

  # Step 1 - Load generator train module and set an optimizer
  gen_module = load_traied_module(HOME_PATH + "Generator_criterion_type_bce_non_saturating", is_disc=False)
  latent_vactor = torch.randn(1, LATENT_SPACE_DIMENSION, device=DEVICE, requires_grad=True)
  optimizer = optim.Adam([latent_vactor], lr=0.0001, betas=(0.5, 0.999))

  # Step 2 - Start optimization progress
  print("Starting GAN restoration progress")
  curr_err = 100.0
  curr_step = 0

  while curr_step < max_iter and curr_err > min_err:
    inter_image = gen_module(latent_vactor)
    degradeted_inter_image = degradetion_func(inter_image)
    loss = criterion(degradeted_inter_image, degradeted_image)
    loss.backward()
    optimizer.step()

    curr_err = loss.item()
    curr_step += 1

    if curr_step % 1000 == 0:
      print("curr_err = {}".format(curr_err))
      print("curr_step = {}".format(curr_step))

  print("Finished GAN restoration progress")

  # Step 3 - Display target image and inverted image
  images = torch.cat((original_image, degradeted_image, gen_module(latent_vactor)))
  display_three_images(images)

# Sample a random image for questions 2-3
dataset = load_CelebA64()
dataloader = create_loader(dataset, batch_size=1)
original_image = next(iter(dataloader)).to(DEVICE)

"""**Question 2 - GAN Inversion**"""

# Question 2 - GAN Inversion
# Degradate function that doesn't do anything
def identity_func(image):
  return image

# Use MSE loss function for optimization progress
criterion = nn.MSELoss()

# Invart image
restore_image(original_image, identity_func, criterion)

"""**Question 3 - GAN Restoration**"""

# Question 3 - GAN Restoration

# Section 1
# Degradate function that adds gaussian noise
gaussian_vector = torch.empty(1, 64, 64).normal_(mean=0., std=0.1).to(DEVICE)
def gaussian_noise(image):
  return image + gaussian_vector

# Use MSE loss function for optimization progress
criterion = nn.L1Loss()

# Restore image
restore_image(original_image, gaussian_noise, criterion)

# Section 2
# Degradate function that deletes a random 8x8 window in the image
import random
#top_left_i = random.randint(0, 56)
#top_left_j = random.randint(0, 56)
top_left_i = 32
top_left_j = 32

def delete_window(image):
  image = transforms.functional.erase(image[0, :, :, :], top_left_i, top_left_j, 8, 8, 0.0)
  image = torch.unsqueeze(image, 0)
  return image

# Use MSE loss function for optimization progress
criterion = nn.L1Loss()

# Restore image
restore_image(original_image, delete_window, criterion, max_iter=5*10**5)